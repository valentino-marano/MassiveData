{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Importing COVID-19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Resources/dpc-covid19-ita-province.json') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing NetworkX and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe contains 108 rows\n",
      "After removing unusable data, Dataframe contains 107 rows\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with COVID data, we need just some columns\n",
    "city_dataframe = pd.DataFrame(d)[['denominazione_provincia', 'lat', 'long']].drop_duplicates()\n",
    "\n",
    "print(\"Dataframe contains \" + str(city_dataframe.count()[0]) + \" rows\")\n",
    "\n",
    "# Remove data having latitude = 0 or longitude = 0 or provincia = \"In fase di definizione/aggiornamento\"\n",
    "city_dataframe.drop(city_dataframe[(city_dataframe['lat'] == 0) | \\\n",
    "                                   (city_dataframe['long'] == 0) | \\\n",
    "                                   (city_dataframe['denominazione_provincia'] == 'In fase di definizione/aggiornamento') \\\n",
    "                                  ].index, inplace = True)\n",
    "\n",
    "city_dataframe.reset_index(drop = True, inplace = True)\n",
    "                        \n",
    "print(\"After removing unusable data, Dataframe contains \" + str(city_dataframe.count()[0]) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>denominazione_provincia</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chieti</td>\n",
       "      <td>42.351032</td>\n",
       "      <td>14.167546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L'Aquila</td>\n",
       "      <td>42.351222</td>\n",
       "      <td>13.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pescara</td>\n",
       "      <td>42.464584</td>\n",
       "      <td>14.213648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Teramo</td>\n",
       "      <td>42.658918</td>\n",
       "      <td>13.704400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matera</td>\n",
       "      <td>40.667512</td>\n",
       "      <td>16.597924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Rovigo</td>\n",
       "      <td>45.071073</td>\n",
       "      <td>11.790070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Treviso</td>\n",
       "      <td>45.667546</td>\n",
       "      <td>12.245074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Venezia</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Verona</td>\n",
       "      <td>45.438390</td>\n",
       "      <td>10.993527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Vicenza</td>\n",
       "      <td>45.547497</td>\n",
       "      <td>11.545971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    denominazione_provincia        lat       long\n",
       "0                    Chieti  42.351032  14.167546\n",
       "1                  L'Aquila  42.351222  13.398438\n",
       "2                   Pescara  42.464584  14.213648\n",
       "3                    Teramo  42.658918  13.704400\n",
       "4                    Matera  40.667512  16.597924\n",
       "..                      ...        ...        ...\n",
       "102                  Rovigo  45.071073  11.790070\n",
       "103                 Treviso  45.667546  12.245074\n",
       "104                 Venezia  45.434905  12.338452\n",
       "105                  Verona  45.438390  10.993527\n",
       "106                 Vicenza  45.547497  11.545971\n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "We are not explicitly adding nodes to graph $\\Rightarrow$ nodes without any edge will not be put in the graph\n",
    "## 1. Iteration over all couples $\\rightarrow$ Cost: $\\mathcal{\\Theta}\\ (\\ n^2\\ )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allCoupleEdges(graph, dataframe, radius):\n",
    "    # O (n)\n",
    "    for i in dataframe.index:\n",
    "\n",
    "        # O (n)\n",
    "        for j in dataframe.index:\n",
    "            if i != j and \\\n",
    "               dataframe.iloc[i, 1] - radius <= dataframe.iloc[j, 1] and \\\n",
    "               dataframe.iloc[i, 1] + radius >= dataframe.iloc[j, 1] and \\\n",
    "               dataframe.iloc[i, 2] - radius <= dataframe.iloc[j, 2] and \\\n",
    "               dataframe.iloc[i, 2] + radius >= dataframe.iloc[j, 2]:\n",
    "                graph.add_edge(dataframe.iloc[i, 0], dataframe.iloc[j, 0])                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Binary search on ordered dataframe $\\rightarrow$ Cost: $\\mathcal{\\Theta}\\ (\\ n \\cdot \\log{} n\\ )$\n",
    "\n",
    "### Utility function\n",
    "Given a dataframe with:\n",
    " - Column 0 $\\rightarrow$ ID\n",
    " - Column 1 $\\rightarrow$ Position  \n",
    " \n",
    "Returns a set of all ID couples within *radius* distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarySearchSingle(dataframe, radius):\n",
    "    # Edges between near cities basing on x position\n",
    "    # Use of dictionary, in this way search of an element costs O(1)\n",
    "    edges = {}\n",
    "    \n",
    "    # Sort dataframe basing on position O (n log n) using quicksort\n",
    "    # Use of tmpDataframe to leave dataframe as received\n",
    "    tmpDataframe = dataframe.sort_values(by = dataframe.columns[1])\n",
    "    tmpDataframe.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # O(n)\n",
    "    for i in tmpDataframe.index:        \n",
    "        # Set pointers to be used in iterative binary search\n",
    "        first = 0\n",
    "        # We just check the left half because we do not need double couples (a, b) and (b, a).\n",
    "        last = i - 1\n",
    "        found = False\n",
    "\n",
    "        # O (log n)\n",
    "        while first <= last and not found:\n",
    "            midpoint = (first + last) // 2\n",
    "        \n",
    "            # Check if element at midpoint position is near enough            \n",
    "            if tmpDataframe.iloc[i, 1] - radius <= tmpDataframe.iloc[midpoint, 1]:\n",
    "                \n",
    "                # If element at midpoint position is the leftmost element within radius distance\n",
    "                # i.e. element at (midpoint - 1) position is too far\n",
    "                if midpoint == 0 or tmpDataframe.iloc[i, 1] - radius > tmpDataframe.iloc[midpoint - 1, 1]:\n",
    "                \n",
    "                    # We add to edges all couples composed by (element at i position, element at j position)\n",
    "                    # for all j from midpoint to i (excluded)\n",
    "                    edges.update([((tmpDataframe.iloc[i, 0], tmpDataframe.iloc[j, 0]), None) \n",
    "                                  for j in range(midpoint, i)])\n",
    "                    found = True\n",
    "                \n",
    "                # Otherwise (element at (midpoint - 1) position is near enough)\n",
    "                # We search in left half\n",
    "                else:\n",
    "                    last = midpoint - 1             \n",
    "                    \n",
    "            # Otherwise we must search in right half\n",
    "            else:\n",
    "                first = midpoint + 1\n",
    "                \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def binarySearchEdges(graph, dataframe, radius):\n",
    "    xEdges = binarySearchSingle(dataframe, radius)\n",
    "    yEdges = binarySearchSingle(dataframe.iloc[:, 0::2],  radius)\n",
    "            \n",
    "    # O(n)\n",
    "    for k in xEdges.keys():\n",
    "        # Searching both for (a,b) and (b,a)\n",
    "        # O(1)\n",
    "        if k in yEdges or k[::-1] in yEdges:\n",
    "            graph.add_edge(*k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Graph of cities\n",
    "Build the graph of provinces P using NetworkX. Each node corresponds to a city and two cities a and b are connected by an edge if the following holds: if x,y is the position of a, then b is in position z,w with z in [x-d,x+d] and w in [y-d, y+d], with d=0.8. The graph is symmetric. Use the latitude and longitude information available in the files to get the position of the cities. This task can be done in several ways. Use the one you think is more efficient.\n",
    "\n",
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_all_couples = nx.Graph()\n",
    "P = nx.Graph()\n",
    "radius = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph using algorithm # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 ms ± 6.56 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "P_all_couples.clear()\n",
    "allCoupleEdges(P_all_couples, city_dataframe, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph using algorithm # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.5 ms ± 646 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "P.clear()\n",
    "binarySearchEdges(P, city_dataframe, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking results of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if P.nodes != P_all_couples.nodes:\n",
    "    raise Exception(\"P.nodes != P_all_couples.nodes\")\n",
    "    \n",
    "if P.edges != P_all_couples.edges:\n",
    "    raise Exception(\"P.edges != P_all_couples.edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create graph of point\n",
    "Generate 2000 pairs of double (x,y) with x in [30,50) and y in [10,20). Repeat the algorithm at step 1, building a graph R using NetworkX where each pair is a node and two nodes are connected with the same rule reported above, still with d=0.08. If the algorithm at step 1 takes too long, repeat step 1. Note that here d=0.08 (and not 0.8 as in the previous item), as in this way the resulting graph is sparser.\n",
    "\n",
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 0.08\n",
    "R = nx.Graph()\n",
    "xMin = 30\n",
    "xMax = 50\n",
    "yMin = 10\n",
    "yMax = 20\n",
    "couples_count = 2000\n",
    "points_dataframe = pd.DataFrame()\n",
    "\n",
    "# Generate column x with couples_count rows of elements in [xMin, xMax)\n",
    "points_dataframe['x'] = np.random.random_sample(couples_count) * (xMax - xMin) + xMin\n",
    "\n",
    "# Generate column y with couples_count rows of elements in [yMin, yMax)\n",
    "points_dataframe['y'] = np.random.random_sample(couples_count) * (yMax - yMin) + yMin\n",
    "\n",
    "# Generate column label with couples_count rows of (x value, y value)\n",
    "points_dataframe['label'] = \"(\" + points_dataframe['x'].astype(str) + \", \" + points_dataframe['x'].astype(str) + \")\"\n",
    "points_dataframe = points_dataframe[['label', 'x', 'y']]\n",
    "\n",
    "# Replace duplicates to have clean data\n",
    "# We just change y value and check that new couple is unique\n",
    "for dup_ind in points_dataframe[points_dataframe.duplicated()].index:\n",
    "    while (points_dataframe['label'].value_counts()[points_dataframe.loc[dup_ind, 'label']]) > 1:\n",
    "        points_dataframe.loc[dup_ind, 'y'] = np.random.random_sample() * (yMax - yMin) + yMin\n",
    "        points_dataframe.loc[dup_ind, 'label'] = \"(\" + str(points_dataframe.loc[dup_ind, 'x']) + \\\n",
    "          \", \" + str(points_dataframe.loc[dup_ind, 'y']) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(46.548328809759255, 46.548328809759255)</td>\n",
       "      <td>46.548329</td>\n",
       "      <td>19.824551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(32.56775347721311, 32.56775347721311)</td>\n",
       "      <td>32.567753</td>\n",
       "      <td>17.371598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(33.88702765255466, 33.88702765255466)</td>\n",
       "      <td>33.887028</td>\n",
       "      <td>10.063531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(46.724556880978554, 46.724556880978554)</td>\n",
       "      <td>46.724557</td>\n",
       "      <td>10.128249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(46.405501607583304, 46.405501607583304)</td>\n",
       "      <td>46.405502</td>\n",
       "      <td>13.252639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>(46.39532706755283, 46.39532706755283)</td>\n",
       "      <td>46.395327</td>\n",
       "      <td>13.908603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>(47.09793985494326, 47.09793985494326)</td>\n",
       "      <td>47.097940</td>\n",
       "      <td>10.089909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>(36.12357947541021, 36.12357947541021)</td>\n",
       "      <td>36.123579</td>\n",
       "      <td>13.082763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>(33.354969381879656, 33.354969381879656)</td>\n",
       "      <td>33.354969</td>\n",
       "      <td>15.756303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>(36.31828423047488, 36.31828423047488)</td>\n",
       "      <td>36.318284</td>\n",
       "      <td>14.736409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         label          x          y\n",
       "0     (46.548328809759255, 46.548328809759255)  46.548329  19.824551\n",
       "1       (32.56775347721311, 32.56775347721311)  32.567753  17.371598\n",
       "2       (33.88702765255466, 33.88702765255466)  33.887028  10.063531\n",
       "3     (46.724556880978554, 46.724556880978554)  46.724557  10.128249\n",
       "4     (46.405501607583304, 46.405501607583304)  46.405502  13.252639\n",
       "...                                        ...        ...        ...\n",
       "1995    (46.39532706755283, 46.39532706755283)  46.395327  13.908603\n",
       "1996    (47.09793985494326, 47.09793985494326)  47.097940  10.089909\n",
       "1997    (36.12357947541021, 36.12357947541021)  36.123579  13.082763\n",
       "1998  (33.354969381879656, 33.354969381879656)  33.354969  15.756303\n",
       "1999    (36.31828423047488, 36.31828423047488)  36.318284  14.736409\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph using algorithm # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell commented because of high time consuming, executed just once with result:\n",
      "1min 25s ± 234 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "#P_all_couples.clear()\n",
    "#allCoupleEdges(P_all_couples, points_dataframe, radius)\n",
    "print('Cell commented because of high time consuming, executed just once with result:')\n",
    "print('1min 25s ± 234 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph using algorithm # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 s ± 6.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "R.clear()\n",
    "binarySearchEdges(R, points_dataframe, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Weight graphs\n",
    "Both P and R can be seen as weighted graphs putting on each edge the distance between the two cities. Modify P and R to weight their edges.\n",
    "\n",
    "### Utility function\n",
    "Given a graph and a dataframe containing all nodes of the graph with:\n",
    " - Column 0 $\\rightarrow$ ID\n",
    " - Column 1 $\\rightarrow$ X Position  \n",
    " - Column 2 $\\rightarrow$ Y Position  \n",
    " \n",
    "adds weight (distance) to each edge of the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightGraph(graph, dataframe):\n",
    "    for edge in graph.edges:\n",
    "        graph.edges[edge]['weight'] = mt.sqrt(((dataframe.loc[dataframe.iloc[:, 0] == edge[0]].iloc[0, 1]) - \\\n",
    "                                         (dataframe.loc[dataframe.iloc[:, 0] == edge[1]].iloc[0, 1])) ** 2 +\\\n",
    "                                        ((dataframe.loc[dataframe.iloc[:, 0] == edge[0]].iloc[0, 2]) - \\\n",
    "                                         (dataframe.loc[dataframe.iloc[:, 0] == edge[1]].iloc[0, 2])) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightGraph(P, city_dataframe)\n",
    "weightGraph(R, points_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Eulerian Path\n",
    "\n",
    "From Wikipedia (https://en.wikipedia.org/wiki/Eulerian_path):\n",
    "In graph theory, an Eulerian trail (or Eulerian path) is a trail in a finite graph that visits every edge exactly once (allowing for revisiting vertices). Similarly, an Eulerian circuit or Eulerian cycle is an Eulerian trail that starts and ends on the same vertex.\n",
    "\n",
    "## Fleury's algorithm\n",
    "Fleury's algorithm is an elegant but inefficient algorithm.\n",
    " 1. Check that graph has all edges in the same component\n",
    " 2. Check that graph has at most 2 vertices of odd degree\n",
    " 3. Choose a vertex of odd degree, if the graph has none choose an arbitrary vertex.  \n",
    "    3.1 Choose next edge in the path to be one whose deletion would not disconnect the graph. If there is no such edge pick the remaining edge left at the current vertex.  \n",
    "    3.2 Use this edge to reach the other node and delete the edge.  \n",
    "    3.3 If current vertex has no more edges it means that the Graph has no more edge. Otherwise return to 3.1\n",
    "    \n",
    "While the graph traversal in Fleury's algorithm is linear in the number of edges, i.e. $\\mathcal{O}\\ (\\ |E|\\ )$, we also need to factor in the complexity of detecting bridges.  \n",
    "If we are to re-run Tarjan's linear time bridge-finding algorithm after the removal of every edge, Fleury's algorithm will have a time complexity of $\\mathcal{O}\\ (\\ |E|^2\\ )$.  \n",
    "A dynamic bridge-finding algorithm of Thorup allows this to be improved to $\\mathcal{O}\\ (\\ |E|\\ \\cdot\\ (\\ log\\ ⁡|E|\\ )^3\\ log\\ log\\ |E|\\ )$, but this is still significantly slower than alternative algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fleury(graph):\n",
    "    # Check if graph is connected\n",
    "    if ! nx.is_connected(graph):\n",
    "        raise Exception(\"Graph is not connected\")\n",
    "        \n",
    "    # Check which nodes have odd degree and raise exception if more than 2 have been found\n",
    "    odd_degree_nodes = []\n",
    "    for node in graph.nodes:\n",
    "        if graph.degree([node]) % 2 != 0:\n",
    "            if len(odd_degree_nodes) == 2:\n",
    "                raise Exception(\"Graph has more than 2 nodes with odd degree\")\n",
    "            \n",
    "            odd_degree_nodes.append(node)\n",
    "    \n",
    "    # Start with a node with odd degree (if any)\n",
    "    if len(odd_degree_nodes) > 0:\n",
    "        node = odd_degree_nodes[0]\n",
    "    else:\n",
    "        node = [*graph.nodes][0]\n",
    "    \n",
    "    end = False\n",
    "    trail = []\n",
    "    while !end:\n",
    "        \n",
    "        # Search edge to node that belong to the same connected component. \n",
    "        # I.e. edge between those 2 nodes is not a bridge \n",
    "        # --> its deletion will not make graph disconnected\n",
    "        not_bridge_neigh = neigh in nx.node_connected_component(P, node) & {*P[node]}\n",
    "        if len(not_bridge_neigh) > 0:\n",
    "            next_node = not_bridge_neigh.pop()\n",
    "                \n",
    "        # If node has at least 1 neighbour\n",
    "        elif len(P[node]) > 0:\n",
    "            next_node = [*P[node]][0]\n",
    "            \n",
    "        else:\n",
    "            end = True\n",
    "            \n",
    "        trail.append(node)\n",
    "        graph.remove_node(node)\n",
    "        node = next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.get_edge_data('Siracusa', 'Ragusa')['weight']\n",
    "[*P['Siracusa']]\n",
    "P.*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierholzer's algorithm\n",
    "Hierholzer's is more efficient than Fleury's algorithm:\n",
    "  1. Choose any starting vertex v, and follow a trail of edges from that vertex until returning to v. It is not possible to get stuck at any vertex other than v, because the even degree of all vertices ensures that, when the trail enters another vertex w there must be an unused edge leaving w. The tour formed in this way is a closed tour, but may not cover all the vertices and edges of the initial graph.\n",
    "    As long as there exists a vertex u that belongs to the current tour but that has adjacent edges not part of the tour, start another trail from u, following unused edges until returning to u, and join the tour formed in this way to the previous tour.\n",
    "    Since we assume the original graph is connected, repeating the previous step will exhaust all edges of the graph.\n",
    "\n",
    "By using a data structure such as a doubly linked list to maintain the set of unused edges incident to each vertex, to maintain the list of vertices on the current tour that have unused edges, and to maintain the tour itself, the individual operations of the algorithm (finding unused edges exiting each vertex, finding a new starting vertex for a tour, and connecting two tours that share a vertex) may be performed in constant time each, so the overall algorithm takes linear time, O ( | E | ) {\\displaystyle O(|E|)} O(|E|).[8]\n",
    "\n",
    "This algorithm may also be implemented with a queue. Because it is only possible to get stuck when the queue represents a closed tour, one should rotate the queue (remove an element from the head and add it to the tail) until unstuck, and continue until all edges are accounted for. This also takes linear time, as the number of rotations performed is never larger than | E | {\\displaystyle |E|} |E|. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    " - connected manual check\n",
    " - odd degree check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#dLong = dataframe.sort_values(by='long')\n",
    "\n",
    "#datas = pd.DataFrame(d)\n",
    "\n",
    "# O(n) Cleaning data\n",
    "# Removing unusable latitude / longitude\n",
    "#for i in range(len(d)):\n",
    "#    if d[i]['lat'] != 0 and d[i]['long'] != 0:\n",
    "#        dLong.append(d[i])\n",
    "\n",
    "# O(n log n)\n",
    "#dLong.sort(key=sortLongFun)\n",
    "\n",
    "#dLat = dLong.copy()\n",
    "\n",
    "# O(n log n)\n",
    "#dLat.sort(key=sortLatFun)  \n",
    "\n",
    "\n",
    "\n",
    "import pixiedust\n",
    "import pdb\n",
    "\n",
    "def sortLatFun(elem):\n",
    "    return elem['lat']\n",
    "\n",
    "def sortLongFun(elem):\n",
    "    return elem['long']\n",
    "\n",
    "def my_print(d):\n",
    "    for i in range(len(d)):\n",
    "        display(d[i]['lat'])\n",
    "        \n",
    "'''\n",
    "def binarySearch(list, item_index):\n",
    "    first = 0\n",
    "    last = len(list)-1\n",
    "\n",
    "    while first <= last:\n",
    "        midpoint = (first + last)//2\n",
    "        if item_index\n",
    "           list[item_index]['lat'] - radius <= list[midpoint]['lat'] and \\\n",
    "           list[item_index]['lat'] + radius >= list[midpoint]['lat'] and \\\n",
    "           list[item_index]['long'] - radius <= list[midpoint]['long'] and \\\n",
    "           list[item_index]['long'] + radius >= list[midpoint]['long']:\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if item < list[midpoint]:\n",
    "                last = midpoint-1\n",
    "            else:\n",
    "                first = midpoint+1\n",
    "\n",
    "    return found\n",
    "'''\n",
    "'''\n",
    "def binarySearch(d, item, item_index):\n",
    "    if len(d) == 0:\n",
    "        return\n",
    "    \n",
    "    midpoint = len(d) // 2\n",
    "    HEAD = \"len:\" + str(len(d)) + \", midpoint: \" + str(midpoint) + \", item_lat: \" + str(item['lat']) + \", midpoint_lat: \" + str(d[midpoint]['lat'])\n",
    "    my_print(d)\n",
    "\n",
    "    if item['lat'] - radius <= d[midpoint]['lat'] and \\\n",
    "       item['lat'] + radius >= d[midpoint]['lat']:\n",
    "        if len(d) >= midpoint and midpoint != 0:\n",
    "            display(HEAD + \" - Calling: d[:\" + str(midpoint) + \"] \")\n",
    "            binarySearch(d[:midpoint], item, item_index)\n",
    "        \n",
    "        if len(d) > midpoint+1:\n",
    "            display(HEAD + \" - Calling: d[\" + str(midpoint+1) + \":] \")\n",
    "            binarySearch(d[midpoint+1:], item, item_index)\n",
    "            \n",
    "        if item['long'] - radius <= d[midpoint]['long'] and \\\n",
    "           item['long'] + radius >= d[midpoint]['long'] and \\\n",
    "           item != d[midpoint]:\n",
    "            display(HEAD + \" - Adding edge\")\n",
    "            P.add_edge(midpoint, item_index)\n",
    "    else:\n",
    "        if item['lat'] < d[midpoint]['lat'] and \\\n",
    "           len(d) >= midpoint and \\\n",
    "           midpoint != 0:\n",
    "            display(HEAD + \" - Else Calling: d[:\" + str(midpoint) + \"] \")\n",
    "            binarySearch(d[:midpoint], item, item_index)\n",
    "        elif len(d) > midpoint + 1:\n",
    "                display(HEAD + \" - Else Calling: d[\" + str(midpoint+1) + \":] \")\n",
    "                binarySearch(d[midpoint+1:], item, item_index)\n",
    "'''\n",
    "'''\n",
    "def binarySearch(d, item):\n",
    "    midpoint = len(d)//2\n",
    "    HEAD = \"len:\" + str(len(d)) + \", midpoint \" + str(midpoint) + \", \" + str(item['lat']) + \", \" + str(d[midpoint]['lat'])\n",
    "    display(HEAD)\n",
    "    if item['lat'] - radius <= d[midpoint]['lat'] and \\\n",
    "       item['lat'] + radius >= d[midpoint]['lat']:\n",
    "        if len(d) >= midpoint:\n",
    "            display(HEAD + \" - Calling: d[:\" + str(midpoint) + \"] \")\n",
    "            binarySearch(d[:midpoint], item)\n",
    "        \n",
    "        if len(d) > midpoint+1:\n",
    "            display(HEAD + \" - Calling: d[\" + str(midpoint+1) + \":] \")\n",
    "            binarySearch(d[midpoint+1:], item)\n",
    "            \n",
    "        if item['long'] - radius <= d[midpoint]['long'] and \\\n",
    "           item['long'] + radius >= d[midpoint]['long'] and \\\n",
    "           item != midpoint:\n",
    "            display(HEAD + \" - Adding edge\")\n",
    "            P.add_edge(midpoint, item)\n",
    "    else:\n",
    "        if item['lat'] < d[midpoint]['lat'] and len(d) >= midpoint:\n",
    "            display(HEAD + \" - Else Calling: d[:\" + str(midpoint) + \"] \")\n",
    "            binarySearch(d[:midpoint], item)\n",
    "        elif len(d) > midpoint + 1:\n",
    "                display(HEAD + \" - Else Calling: d[\" + str(midpoint+1) + \":] \")\n",
    "                binarySearch(d[midpoint+1:], item)\n",
    "'''                 \n",
    "\n",
    "import random\n",
    "display(len(d))\n",
    "d = random.sample(d, 1500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
